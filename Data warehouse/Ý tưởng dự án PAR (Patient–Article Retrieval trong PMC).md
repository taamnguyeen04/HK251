## 1. Má»¥c tiÃªu

XÃ¢y dá»±ng há»‡ thá»‘ng tÃ¬m kiáº¿m vÃ  liÃªn káº¿t tá»± Ä‘á»™ng giá»¯a **bÃ i bÃ¡o y khoa** (trong PMC) vÃ  **thÃ´ng tin bá»‡nh nhÃ¢n**.  
Há»‡ thá»‘ng vá»«a giÃºp truy há»“i cÃ¡c bÃ i bÃ¡o liÃªn quan cho bÃ¡c sÄ© (hoáº·c nghiÃªn cá»©u viÃªn), vá»«a lÆ°u trá»¯, cáº­p nháº­t vÃ  gáº¯n káº¿t dá»¯ liá»‡u bá»‡nh nhÃ¢n Ä‘á»ƒ phá»¥c vá»¥ phÃ¢n tÃ­ch vÃ  há»— trá»£ ra quyáº¿t Ä‘á»‹nh.

---

## 2. Dá»¯ liá»‡u Ä‘áº§u vÃ o

- **corpus.json**: chá»©a táº­p bÃ i bÃ¡o vá»›i metadata cÆ¡ báº£n.
- **PMID2MeSH.json**: Ã¡nh xáº¡ bÃ i bÃ¡o vá»›i tá»« khÃ³a/nhÃ£n MeSH.
- **PMC-Patients.json** vÃ  **patient2article_relevance.json**: mÃ´ táº£ má»‘i liÃªn káº¿t giá»¯a bá»‡nh nhÃ¢n vÃ  bÃ i bÃ¡o liÃªn quan.

Má»—i bÃ i bÃ¡o Ä‘Æ°á»£c biá»ƒu diá»…n dÆ°á»›i dáº¡ng vector embedding tá»« chuá»—i:
`[CLS] title [SEP] abstract [SEP]`

---

## 3. MÃ´ hÃ¬nh biá»ƒu diá»…n

- Sá»­ dá»¥ng **PubMedBERT** Ä‘á»ƒ embed bÃ i bÃ¡o (paper embeddings).
- CÃ³ thá»ƒ thÃªm nhÃ£n (labels/MeSH terms) Ä‘á»ƒ tinh chá»‰nh khÃ´ng gian embedding â†’ phá»¥c vá»¥ phÃ¢n cá»¥m (clustering) vÃ  gÃ¡n nhÃ£n (classification).
- CÃ¡c vector nÃ y Ä‘Æ°á»£c lÆ°u vÃ o **database vector** Ä‘á»ƒ truy váº¥n nhanh.

---

## 4. Nhiá»‡m vá»¥ chÃ­nh
### 4.1. Classification (GÃ¡n nhÃ£n bÃ i bÃ¡o)
- DÃ¹ng embedding cá»§a paper + embedding cá»§a nhÃ£n.
- GiÃºp gáº¯n bÃ i bÃ¡o vá»›i chá»§ Ä‘á» (MeSH terms), Ä‘á»“ng thá»i há»— trá»£ downstream task nhÆ° phÃ¢n tÃ­ch hoáº·c tá»• chá»©c tri thá»©c.

### 4.2. Link Prediction (Dá»± Ä‘oÃ¡n quan há»‡)

- Dá»±a trÃªn file _patient2article_relevance.json_, mÃ´ hÃ¬nh há»c cÃ¡ch xÃ¡c Ä‘á»‹nh má»‘i quan há»‡ **bÃ i bÃ¡o â†” bá»‡nh nhÃ¢n**.
- Cho phÃ©p má»Ÿ rá»™ng: tá»« má»™t bá»‡nh nhÃ¢n â†’ tÃ¬m cÃ¡c bÃ i bÃ¡o liÃªn quan (Patient-to-Article Retrieval).
- NgÆ°á»£c láº¡i, tá»« má»™t bÃ i bÃ¡o â†’ tÃ¬m bá»‡nh nhÃ¢n cÃ³ Ä‘áº·c Ä‘iá»ƒm phÃ¹ há»£p (Article-to-Patient Link).

### 4.3. Retrieval (Truy há»“i thÃ´ng tin)

- Khi cÃ³ **mÃ´ táº£ bá»‡nh nhÃ¢n má»›i** (patient description query), há»‡ thá»‘ng:
    1. Encode mÃ´ táº£ thÃ nh vector.
    2. So khá»›p vá»›i vector trong DB (retrieval).
    3. Ãp dá»¥ng pipeline hai táº§ng:
        - **Stage 1**: PubMedBERT retrieval (zero-shot).
        - **Stage 2**: Rerank báº±ng Cross-Encoder Ä‘á»ƒ tÄƒng chÃ­nh xÃ¡c.
## Há»c Ä‘a nhiá»‡m (Multi-task Learning)

- CÃ¡c head (classification, link prediction, retrieval) cÃ¹ng há»c trÃªn ná»n embedding chung.
    
- Loss tá»•ng há»£p tá»« nhiá»u nhiá»‡m vá»¥ giÃºp encoder há»c Ä‘Æ°á»£c **khÃ´ng gian biá»ƒu diá»…n Ä‘a dá»¥ng**: vá»«a phÃ¢n loáº¡i tá»‘t, vá»«a dá»± Ä‘oÃ¡n quan há»‡ chÃ­nh xÃ¡c, vá»«a há»— trá»£ retrieval hiá»‡u quáº£.
    
- ÄÃ¢y chÃ­nh lÃ  tinh tháº§n cá»§a **MHA** trong paper: má»™t backbone, nhiá»u task head, huáº¥n luyá»‡n Ä‘á»“ng thá»i.

---
---
---
---
# Pipeline 2 Phase: Pretraining â†’ Fine-tuning

## **Phase 1: Unsupervised Pretraining (11M abstracts)**

**Má»¥c tiÃªu:** há»c embedding tá»‘t, chÆ°a cáº§n nhÃ£n.

### CÃ¡c chiáº¿n lÆ°á»£c kháº£ thi:
1. **MLM (Masked Language Modeling)**
    - Tiáº¿p tá»¥c pretrain PubMedBERT trÃªn corpus 11M cá»§a báº¡n.
    - Má»¥c Ä‘Ã­ch: domain adaptation, model quen vÄƒn phong + tá»« vá»±ng má»›i.
2. **Contrastive Pretraining tá»« metadata (khÃ´ng cáº§n nhÃ£n thá»§ cÃ´ng)**
    - Positive pairs:
        - (title, abstract)
        - (abstract, conclusion / intro)
        - (citing paper, cited paper)
    - Negative: random.
    - Loss = InfoNCE.
    - Æ¯u: embedding há»c trá»±c tiáº¿p cÃ¡ch â€œphÃ¢n biá»‡t vÄƒn báº£n liÃªn quan vs khÃ´ng liÃªn quanâ€.
        
ğŸ‘‰ Náº¿u muá»‘n embedding tá»‘t cho retrieval, **contrastive learning lÃ  báº¯t buá»™c**, MLM chá»‰ nÃªn lÃ  bÆ°á»›c phá»¥ Ä‘á»ƒ adapt.

---

## **Phase 2: Supervised Fine-tuning (32k MeSH + 167k relevance)**
**Má»¥c tiÃªu:** align encoder vá»›i ontology MeSH vÃ  task PAR.
### Multi-task training:
- Loss function:
    `L = Î± * L_contrastive + Î² * L_mesh + Î³ * L_relevance`
    - `L_contrastive`: contrastive loss tá»« phase 1 (cÃ³ thá»ƒ giá»¯ nháº¹ Ä‘á»ƒ regularize).
    - `L_mesh`: BCE loss cho multi-label MeSH classification.
    - `L_relevance`: contrastive/triplet loss cho patientâ€“article relevance.
- CÃ¡ch chia batch:
    - 1 batch contrastive (unsup).
    - 1 batch MeSH.
    - 1 batch patient relevance.
    - Cá»™ng loss theo há»‡ sá»‘.

ğŸ‘‰ BÆ°á»›c nÃ y sáº½ trÃ¡nh overfit vÃ¬ model Ä‘Ã£ â€œcá»©ngâ€ nhá» pretraining 11M.

---
# âš¡ Má»™t sá»‘ máº¹o Ä‘á»ƒ mÃ´ hÃ¬nh tá»‘t hÆ¡n â€œmá»™t chÃºtâ€:

1. **Layer-wise learning rate decay** khi fine-tune:
    - Encoder layers LR nhá».
    - Classification head LR lá»›n.
2. **Hard negative mining** cho contrastive:
    - Negative = doc cÃ¹ng disease nhÆ°ng khÃ¡c treatment â†’ khÃ³ phÃ¢n biá»‡t.
3. **Curriculum training**:
    - Phase 1 chá»‰ unsupervised.
    - Phase 2 supervised nhÆ°ng ban Ä‘áº§u LR nhá» + Î± lá»›n (Æ°u tiÃªn unsup).
    - Sau vÃ i epoch â†’ tÄƒng dáº§n Î², Î³ (Æ°u tiÃªn supervised).
4. **Pseudo-labeling** sau fine-tune:
    - DÃ¹ng model Ä‘Ã£ fine-tuned â†’ sinh thÃªm MeSH/patient label cho data unlabelled.
    - Re-train láº¡i â†’ model align hÆ¡n.



---
---
---
---
---
---
---
---

Tá»•ng quan chiáº¿n lÆ°á»£c (tÃ³m táº¯t)

Unsupervised backbone trÃªn 11M (contrastive pretrain) â€” báº¯t buá»™c Ä‘á»ƒ cÃ³ embedding tá»‘t cho retrieval & clustering.

Weak / distant supervision â€” dÃ¹ng MeSH, metadata, string-match, UMLS Ä‘á»ƒ gÃ¡n nhÃ£n táº¡m cho nhiá»u paper hÆ¡n.

Pseudo-labeling + self-training loop â€” má»Ÿ rá»™ng nhÃ£n MeSH/patient báº±ng model Ä‘Ã£ fine-tune, lá»c báº±ng confidence.

Label propagation trÃªn graph â€” gÃ¡n nhÃ£n qua cáº¥u trÃºc citation / co-authorship / similarity graph.

Active learning / human-in-loop â€” chá»‰ cho bÃ¡c sÄ©/annotator xem top uncertain samples.

Multi-task fine-tune: káº¿t há»£p táº¥t cáº£ (MeSH, relevance) vá»›i regularization tá»« unsupervised contrastive.

Káº¿t há»£p cÃ¡c bÆ°á»›c trÃªn sáº½ cho hiá»‡u quáº£ tá»‘t hÆ¡n: unsupervised cung cáº¥p backbone á»•n Ä‘á»‹nh, weak supervision + pseudo-labeling tÄƒng coverage nhÃ£n, label propagation táº­n dá»¥ng cáº¥u trÃºc tÃ i liá»‡u.

Chi tiáº¿t giáº£i phÃ¡p & cÃ¡ch triá»ƒn khai (theo thá»© tá»± Æ°u tiÃªn)
A. code pháº§n Pretrain contrastive trÃªn 11M (unsupervised)
Má»¥c tiÃªu: há»c embedding domain-specific cho retrieval vÃ  clustering.
Method: InfoNCE / SimCLR style using pairs: (title, abstract).
Batch size: cÃ ng lá»›n cÃ ng tá»‘t (128â€“1024)
Embedding projection dim:theo sá»‘ chiá»u cá»§a "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext", L2-normalize.
Káº¿t quáº£ mong Ä‘á»£i: embedding giÃºp tÃ¬m gáº§n nhau cÃ¡c paper tÆ°Æ¡ng tá»± â†’ cÆ¡ sá»Ÿ cho bÆ°á»›c label propagation vÃ  pseudo-label.

B. Weak / Distant Supervision (má»Ÿ rá»™ng MeSH & patient labels)

Nguá»“n tÃ­n hiá»‡u:

PMID2MeSH: map sáºµn cho má»™t sá»‘ papers â†’ seed labels.

String matching / synonyms: dÃ¹ng UMLS / MeSH synonyms / scispacy NER Ä‘á»ƒ detect disease/drug/phenotype trong abstract â†’ map láº¡i MeSH hoáº·c cluster má»›i.

Metadata signals: journal, title keywords, citation edges, references, authors â€” dÃ¹ng rules Ä‘á»ƒ gÃ¡n nhÃ£n táº¡m.

Cross-document heuristics: náº¿u nhiá»u paper cite same review, inherit its MeSH.

Practical:

DÃ¹ng scispacy + UMLS lookup Ä‘á»ƒ tÃ¬m candidate MeSH per abstract.

GÃ¡n confidence score theo rule (exact match high, fuzzy match tháº¥p).

LÆ°u nhÃ£n â€œsoftâ€ (probability) chá»© khÃ´ng ghi Ä‘Ã¨ nhÃ£n gá»‘c.

C. Pseudo-labeling / Self-training loop (scale-up labels automatically)

Quy trÃ¬nh:

Fine-tune MeSH classifier + relevance head trÃªn 32k MeSH + 100k patient (supervised).

Ãp model lÃªn pháº§n unlabeled (11M minus labeled). Láº¥y nhá»¯ng dá»± Ä‘oÃ¡n cÃ³ confidence cao > Ï„.

Ï„ ban Ä‘áº§u cao (0.9) â†’ trÃ¡nh noise. Sau má»™t vÃ²ng, háº¡ Ï„ xuá»‘ng 0.8 Ä‘á»ƒ thÃªm volume.

ThÃªm pseudo-labeled examples vÃ o train set (gÃ¡n weight tháº¥p hoáº·c dÃ¹ng label smoothing).

Re-train model (hoáº·c continue fine-tune) vá»›i mix of true labels + pseudo labels (use smaller lr on pseudo).

Láº·p láº¡i 2â€“4 vÃ i láº§n; dÃ¹ng validation strict Ä‘á»ƒ kiá»ƒm soÃ¡t drift.

Hyperparams khá»Ÿi Ä‘iá»ƒm:

Initial Ï„ = 0.9, second round Ï„ = 0.85, third Ï„ = 0.8.

Weight for pseudo labels in loss: 0.5 (trÆ°á»›c Ä‘Ã³ 1.0 cho ground-truth).

Max percent of unlabeled accepted per round: 5â€“10% of corpus Ä‘á»ƒ giáº£m noise.

D. Graph-based label propagation (táº­n dá»¥ng citation / similarity graph)

XÃ¢y graph nodes = papers; edges = citation edges vÃ  similarity edges (k-NN in embedding space, k=5â€“20).

Seed nodes = papers cÃ³ MeSH (32k) + high-confidence pseudo-labeled.

Sá»­ dá»¥ng Label Propagation / Graph Neural Network (GCN) Ä‘á»ƒ lan tá»a label probabilities.

Äiá»u chá»‰nh: normalize edge weights; giá»›i háº¡n propagation depth; early stopping based on validation.

Advantages: lan nhÃ£n tá»‘t cho cá»¥m tÃ i liá»‡u liÃªn quan - há»¯u Ã­ch khi MeSH cover má»™t sá»‘ chá»§ Ä‘á» nhÆ°ng thiáº¿u cho nhiá»u paper.

E. Clustering + cluster labeling

Cluster 11M embedding (approx): dÃ¹ng scalable approach â€” HNSW/IVF + k-means on IVF centroids hoáº·c MiniBatchKMeans trÃªn sample, sau Ä‘Ã³ assign.

Cho má»—i cluster, aggregate keywords / top-N tf-idf terms â†’ propose MeSH / label for cluster.

Human-in-loop: chá»‰ review top clusters (vÃ­ dá»¥ 1k clusters) Ä‘á»ƒ gÃ¡n nhÃ£n nhanh hÃ ng loáº¡t.

F. Zero-shot / LLM-based labeling (khi cáº§n cover niche)

DÃ¹ng LLM (e.g., instruction-tuned biomedical LLM hoáº·c general LLM with prompt) Ä‘á»ƒ gá»£i MeSH candidates per abstract/title.

Æ¯u: cÃ³ thá»ƒ nhanh chÃ³ng táº¡o nhÃ£n cho cÃ¡c paper láº¡; NhÆ°á»£c: chi phÃ­ & cáº§n kiá»ƒm soÃ¡t cháº¥t lÆ°á»£ng.

DÃ¹ng lÃ m nguá»“n weak label káº¿t há»£p confidence scoring.

G. Hard negative mining & curriculum

Khi há»c relevance, náº¿u nhÃ£n bá»‹ imbalanced, mining hard negatives tá»« papers cÃ³ cÃ¹ng MeSH nhÆ°ng khÃ´ng relevant â†’ cáº£i thiá»‡n discriminative power.

Má»™t pipeline káº¿t há»£p máº«u (Ã¡p dá»¥ng ngay)

Pretrain contrastive trÃªn 11M â†’ lÆ°u embeddings.

Seed expansion: apply scispacy(UMLS)/string-match â†’ generate soft MeSH labels for ~X% papers.

Fine-tune supervised on true labels (32k MeSH + 100k patient) + weighted soft labels.

Pseudo-label pass 1: predict unlabeled â†’ accept high-confidence (Ï„=0.9) â†’ add to training as pseudo (weight 0.5).

Re-train (or continue) with mixed dataset.

Label propagation on citation + k-NN graph â†’ smooth labels across graph.

Cross-encoder rerank fine-tune using high-quality relevance pairs.

Active learning: sample most uncertain or high-impact clusters for human annotation to bootstrap next loop.
